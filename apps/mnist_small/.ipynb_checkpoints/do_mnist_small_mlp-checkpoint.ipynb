{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "from layer_for_theano import *\n",
    "#print __layer_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset in 2.8 secs\n",
      "(50000L, 196L)\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "import time\n",
    "\n",
    "class dataset_mnist_small:\n",
    "    def __init__(self):\n",
    "        if 0: # no requirement for gzip, but big file\n",
    "            f = open('mnist_14x14.pkl', 'rb')\n",
    "            train_set, valid_set, test_set = cPickle.load(f)\n",
    "            f.close()\n",
    "        else: # requiring gzip           \n",
    "            f = gzip.open('mnist_14x14.pkl.gz','rb')\n",
    "            train_set, valid_set, test_set = cPickle.load(f)\n",
    "            f.close()\n",
    "\n",
    "        self.xs_tr, ys_tr = train_set\n",
    "        self.xs_val, ys_val = valid_set\n",
    "        self.xs_te, ys_te = test_set\n",
    "\n",
    "        self.ys_tr =  ys_tr.astype(np.int32)\n",
    "        self.ys_val = ys_val.astype(np.int32)\n",
    "        self.ys_te =  ys_te.astype(np.int32)\n",
    "\n",
    "t0 = time.time()\n",
    "        \n",
    "ds =  dataset_mnist_small()  \n",
    "print 'load dataset in %.1f secs' % (time.time()-t0)\n",
    "\n",
    "print ds.xs_tr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinear activation function =  Elemwise{tanh,no_inplace}\n",
      "before training, err= 0.91\n",
      "now training, cost =  2.33572144116\n",
      "after training, err= 0.7\n"
     ]
    }
   ],
   "source": [
    "from sgd_for_theano import *\n",
    "class mlp_small(tt_sgd_model):\n",
    "    def __init__(self):\n",
    "        #784\n",
    "        dim = 196\n",
    "        nc = 10\n",
    "\n",
    "        self.layers = []\n",
    "        self.layers += [InputLayer(dim)]\n",
    "\n",
    "        nonlinearfunc = T.tanh #T.nnet.sigmoid #rectify #rectify\n",
    "        print 'nonlinear activation function = ', nonlinearfunc\n",
    "        self.layers += [ HiddenLayer(self.layers[-1], n_out = 500,  activation = T.tanh)]\n",
    "        self.layers += [ HiddenLayer(self.layers[-1], n_out = nc,  activation = None)]\n",
    "        self.layers +=  [ SoftmaxLayer(self.layers[-1])]\n",
    "\n",
    "        target = T.ivector('target')\n",
    "        output_eval = self.layers[-1].output()\n",
    "        self.cost_eval = mcloss_negli(output_eval, target)\n",
    "        self.err_eval = mc_error(output_eval, target)\n",
    "        self.validate_model = theano.function([self.layers[0].input, target], self.err_eval)\n",
    "        self.cost_model = theano.function([self.layers[0].input, target], self.cost_eval)\n",
    "\n",
    "        output_tr = self.layers[-1].output(dropout_training=True)\n",
    "        self.cost_tr = mcloss_negli(output_eval, target)\n",
    "\n",
    "        learning_rate = 0.13\n",
    "        #all_para = all_parameters(self.layers[-1])\n",
    "        all_para = self.get_all_parameters()\n",
    "        updates = gen_updates_sgd(self.cost_tr, all_para, learning_rate)\n",
    "        self.train_model = theano.function([self.layers[0].input, target], self.cost_tr, updates=updates)\n",
    "\n",
    "model = mlp_small()\n",
    "\n",
    "if 1: #unit test\n",
    "    import sys\n",
    "    model._unit_test(ds.xs_tr[0:100], ds.ys_tr[0:100])\n",
    "    #sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'n_train_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e29920e378a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merr_list_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_list_tr\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msgd_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mys_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs_te\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mys_te\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\github\\babyl\\sgd_for_theano.py\u001b[0m in \u001b[0;36msgd_batch\u001b[1;34m(sgd_model, xs_tr, ys_tr, xs_val, ys_val, batch_size, n_epochs)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m#validation_frequency = 10 #min(n_tr_batches, patience / 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mvalidation_frequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_tr_batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'n_train_batches' is not defined"
     ]
    }
   ],
   "source": [
    "def sgd_batch(sgd_model, xs_tr, ys_tr,  xs_val, ys_val, batch_size = 100, n_epochs=20):\n",
    "    n_tr_batches = xs_tr.shape[0]/batch_size\n",
    "    n_val_batches = xs_val.shape[0]/batch_size\n",
    "    if n_tr_batches * batch_size < xs_tr.shape[0]:\n",
    "        n_tr_batches += 1\n",
    "    if n_val_batches * batch_size < xs_val.shape[0]:\n",
    "        n_val_batches += 1\n",
    "\n",
    "    #validation_frequency = 10 #min(n_tr_batches, patience / 2)\n",
    "\tvalidation_frequency = n_tr_batches\n",
    "\n",
    "    best_model = copy.deepcopy(sgd_model)\n",
    "    best_validation_loss = np.inf\n",
    "\n",
    "    epoch = 0\n",
    "\n",
    "    inds_for_batch_sampling = range(0, xs_tr.shape[0])\n",
    "    np.random.shuffle(inds_for_batch_sampling)\n",
    "\n",
    "    err_list_val = []\n",
    "    err_list_tr = []\n",
    "    bstop = False\n",
    "    while (epoch < n_epochs and bstop == False):\n",
    "        epoch += + 1\n",
    "        for bi in xrange(n_tr_batches):\n",
    "\n",
    "            p0 = bi * batch_size\n",
    "            p1 = min((bi + 1) * batch_size, xs_tr.shape[0])\n",
    "            inds_i = inds_for_batch_sampling[p0: p1]\n",
    "            xs_tr_i = xs_tr[inds_i]\n",
    "            ys_tr_i = ys_tr[inds_i]\n",
    "\n",
    "\n",
    "            minibatch_avg_cost = sgd_model.train_model(xs_tr_i, ys_tr_i)\n",
    "            print minibatch_avg_cost,\n",
    "            if math.isnan(minibatch_avg_cost):\n",
    "                print '\\n find nan, stop'\n",
    "                bstop = True\n",
    "                break\n",
    "\n",
    "            iter = (epoch - 1) * n_tr_batches + bi\n",
    "            if (iter + 1) % validation_frequency == 0:\n",
    "                val_cost = []\n",
    "                for jj in xrange(n_val_batches):\n",
    "                    p0 = jj* batch_size\n",
    "                    p1 = min((jj + 1) * batch_size, xs_val.shape[0])\n",
    "                    xj_val = xs_val[p0: p1]\n",
    "                    yj_val = ys_val[p0: p1]\n",
    "                    val_cost.append( sgd_model.validate_model(xj_val, yj_val))\n",
    "\n",
    "                err_list_val.append(np.mean(val_cost))\n",
    "\n",
    "                this_validation_loss = np.mean(val_cost)\n",
    "                if 1:\n",
    "                    print '\\n epoch %i, minibatch %i/%i, validation error %f ' % \\\n",
    "                        (epoch, bi + 1, n_tr_batches, this_validation_loss),\n",
    "\n",
    "                tr_cost = []\n",
    "                for jj in xrange(n_tr_batches):\n",
    "                    p0 = jj* batch_size\n",
    "                    p1 = min((jj + 1) * batch_size, xs_tr.shape[0])\n",
    "                    xj = xs_tr[p0: p1]\n",
    "                    yj = ys_tr[p0: p1]\n",
    "                    tr_cost.append( sgd_model.validate_model(xj, yj))\n",
    "                err_list_tr.append(np.mean(tr_cost))\n",
    "\n",
    "                if 1:\n",
    "                    print 'training error %f' % np.mean(tr_cost)\n",
    "\n",
    "                # improve patience if loss improvement is good enough\n",
    "                if this_validation_loss < best_validation_loss:\n",
    "                    best_validation_loss = this_validation_loss\n",
    "                    best_model = copy.deepcopy(sgd_model)\n",
    "\n",
    "        if verbose>0: #randomly shuffling. but not efficient, and ??? cause error!!!\n",
    "            print 'randomly shuffling...'\n",
    "            np.random.shuffle(inds_for_batch_sampling)\n",
    "\n",
    "    return best_validation_loss, best_model, err_list_val, err_list_tr\n",
    "\n",
    "best_err, best_model,err_list_val, err_list_tr =  sgd_batch(model, ds.xs_tr, ds.ys_tr, ds.xs_te, ds.ys_te, batch_size=600, n_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
